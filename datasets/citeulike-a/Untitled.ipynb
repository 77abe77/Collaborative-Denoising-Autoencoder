{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "path = 'users.dat'\n",
    "\n",
    "input_vect_size = 0\n",
    "with open(path, 'rb') as input_file:\n",
    "    for line in input_file:\n",
    "        line = line.strip()\n",
    "        line = line.split()[1:]\n",
    "        for item in line:\n",
    "            if int(item) > input_vect_size:\n",
    "                input_vect_size = int(item)\n",
    "            \n",
    "\n",
    "with open(path, 'rb') as input_file:\n",
    "    train_set = []\n",
    "    val_set = []\n",
    "    for line in input_file:\n",
    "        line = line.strip()\n",
    "        line = line.split()i\n",
    "        #num_saved_items = int(line[0])\n",
    "        #indices = []\n",
    "        \n",
    "        full_data = []\n",
    "        for i in range(1, len(line)):\n",
    "            full_data.append(int(i))\n",
    "        training_data = get_training_data(np.array(full_data))\n",
    "        val_set.append(make_sparse_from_raw_set(full_data, input_vect_size))\n",
    "        train_set.append(make_sparse_from_raw_set(training_data, input_vect_size))\n",
    "        \n",
    "            #indices.append([0, int(line[i]) - 1])\n",
    "        #values = [1] * num_saved_items\n",
    "        #shape = [1, input_vect_size]\n",
    "        #sv = tf.SparseTensor(indices=indices, values=values, shape=shape)\n",
    "\n",
    "# Need to get the sampled on from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sess = tf.Session()\n",
    "dv = tf.sparse_tensor_to_dense(sv)\n",
    "res = sess.run(dv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.where(res > 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sparse_from_raw_set(raw_set, size):\n",
    "    indices = [[0, i - 1] for i in raw_set]\n",
    "    values = [1] * len(indices)\n",
    "    shape = [1, size]\n",
    "    #return [indices, values, shape]\n",
    "    return tf.SparseTensor(indices=indices, values=values, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(full_dataset_one_d):\n",
    "    '''Input: 1-D vector of just the item numbers that are included in\n",
    "        in the full dataset\n",
    "       Output: 2-D with the first dimension holding the test set that\n",
    "               omits 20% of the data, and the second dimension including\n",
    "               the full set. In this application the validation set is\n",
    "               the full set.\n",
    "    '''\n",
    "    #TODO - Might need to check that training set statisfies a min length\n",
    "    full_set = list(full_dataset_one_d)\n",
    "    ind = np.random.randint(1, len(full_dataset_one_d), len(full_dataset_one_d))\n",
    "    train_set_ind = np.where(ind <= 0.8 * len(full_dataset_one_d))[0]\n",
    "    train_set = full_set[train_set_ind]\n",
    "    \n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b, c = get_validation_set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1630,  2316,  2525,  2845,  2930,  3170,  3296,  3331,  3403,\n",
       "        3594,  3769,  3949,  4661,  4870,  4888,  5113,  5323,  5324,\n",
       "        5613,  5990,  6102,  6873,  6967,  7105,  7800,  7866,  8902,\n",
       "        9906, 10007, 10203, 10287, 10507, 10587, 11008, 11104, 11225,\n",
       "       11852, 11918, 12683, 12715, 12801, 12803, 12804, 12830, 12915,\n",
       "       13171, 13362, 13922, 13923, 14661, 14675, 14850, 15025, 15164,\n",
       "       15190, 15281, 15299, 15335, 15832, 15893, 16162, 16423])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885714285714\n"
     ]
    }
   ],
   "source": [
    "len_b = b.shape[0]\n",
    "len_a = a.shape[0]\n",
    "print float(len_b) / len_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "W_init_val = [tf.constant(range(i, i+2), dtype=tf.float32) for i in range(1, 7, 2)]\n",
    "W_prime_init_val = [tf.constant(range(i, i+2), dtype=tf.float32) for i in range(7, 13, 2)]\n",
    "b_prime_init_val = [tf.constant(2.0, dtype=tf.float32) for _ in xrange(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "\n",
    "y_0 = [[1, 0, 1]]\n",
    "y = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "# Test Gradients\n",
    "weight = dict()\n",
    "# weight['W'] = [tf.Variable(seq) for seq in W_init_val]\n",
    "# weight['W_prime'] = [tf.Variable(seq) for seq in W_prime_init_val]\n",
    "# weight['b'] = tf.Variable(tf.constant([[1.0, 1.0]], dtype=tf.float32))\n",
    "# weight['b_prime'] = [tf.Variable(seq) for seq in b_prime_init_val]\n",
    "\n",
    "#tf.pack(weight['W_prime'])[0]\n",
    "weight['W'] = tf.Variable(W_init_val, name='W') \n",
    "weight['W_prime'] = tf.Variable(W_prime_init_val, name='W_prime')\n",
    "weight['b'] = tf.Variable(tf.constant([[1.0, 1.0]], dtype=tf.float32), name='b')\n",
    "weight['b_prime'] = tf.Variable(b_prime_init_val, dtype=tf.float32, name='b_prime') \n",
    "\n",
    "\n",
    "z = tf.add(tf.matmul(y, weight['W']), weight['b'])\n",
    "y_hat = tf.add(tf.matmul(z, tf.transpose(weight['W_prime'])), weight['b_prime'])\n",
    "\n",
    "loss_0 = tf.nn.l2_loss(tf.sub(y, y_hat))\n",
    "# #loss_1 = tf.nn.l2_loss(tf.sub(y, y_hat))\n",
    "# #cost = 0.5 * tf.reduce_sum(tf.nn.l2_loss(tf.sub(y, y_hat)))\n",
    "\n",
    "\n",
    "# # W_var_before = [sess.run(var) for var in weight['W']]\n",
    "# # W_prime_var_before = [sess.run(var) for var in weight['W_prime']]\n",
    "\n",
    "# #Gradient\n",
    "# #dw_0 = tf.gradients(loss_0, [weight['W'][0]])[0]\n",
    "# #dw_prime_0 = tf. gradients(loss_0, [weight['W_prime'][0]])[0]\n",
    "dw_prime_x = optimizer.compute_gradients(loss_0, var_list=[weight['W'], weight['W_prime'], weight['b'], weight['b_prime']])[1][0] #var_list=[weight['W_prime']])[0][0]\n",
    "# #dw_1 = tf.gradients(loss_0, [weight['W'][1]])[0]\n",
    "# #dw_prime_1 = tf. gradients(loss_0, [weight['W_prime'][1]])[0]\n",
    "\n",
    "# #W_var = [sess.run(var) for var in weight['W']]\n",
    "# #W_prime_var = [sess.run(var) for var in weight['W_prime']]\n",
    "\n",
    "# #z_out, y_hat_out, loss, grad_w0, grad_w_prime0, grad_w1, grad_w_prime1 = sess.run((z, y_hat, loss_0, dw_0, dw_prime_0, dw_1, dw_prime_1), feed_dict={y: y_0})\n",
    "sparse_update = tf.scatter_update(weight['W_prime'], [0, 2], tf.gather(dw_prime_x, [0, 2]))\n",
    "# # #normalized_weights = [tf.nn.l2_normalize(var, 0) for var in weight.iteritems()]\n",
    "# # #w_sum = tf.reduce_sum(normalized_weights)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "#a = sess.run(dw_prime_x, feed_dict={y: y_0})[1][0]\n",
    "W_prime_var_before = sess.run(weight['W_prime'])\n",
    "# print sess.run(dw_prime_x, feed_dict={y: y_0})\n",
    "sess.run(sparse_update, feed_dict={y: y_0})\n",
    "# # #reg_sum = sess.run(w_sum)\n",
    "W_prime_var = sess.run(weight['W_prime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  854.,  1098.],\n",
       "       [ 1085.,  1395.],\n",
       "       [ 1302.,  1674.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.   8.]\n",
      " [  9.  10.]\n",
      " [ 11.  12.]]\n",
      "\n",
      "[[  854.  1098.]\n",
      " [    9.    10.]\n",
      " [ 1302.  1674.]]\n"
     ]
    }
   ],
   "source": [
    "print W_prime_var_before\n",
    "print ''\n",
    "print W_prime_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = 0.1\n",
    "loss = tf.nn.l2_loss(tf.sub(y, y_hat))\n",
    "\n",
    "dloss_d = lambda var: optimizer.compute_gradients(loss, var_list=[var])[0][0]\n",
    "dCost_d = lambda var: dloss_d(var) - tf.mul(l, var)\n",
    "\n",
    "grad_op = lambda var: optimizer.apply_gradients([[dCost_d(var), var]])\n",
    "W_var_before = [sess.run(var) for var in weight['W']]\n",
    "#cost = lambda var: loss - tf.mul(l, var)\n",
    "#cost = 0.5 * tf.reduce_sum([tf.nn.l2_loss(vect) for vect in tf.sub(z_0, z)])\n",
    "#cost = 0.5 * tf.reduce_sum(tf.nn.l2_loss(tf.sub(z_0, z)))\n",
    "sess.run(grad_op(weight['W'][0]), feed_dict={y: y_0})\n",
    "W_var = [sess.run(var) for var in weight['W']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.,  2.], dtype=float32),\n",
       " array([ 3.,  4.], dtype=float32),\n",
       " array([ 5.,  6.], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_var_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-41.9489975, -45.5779953], dtype=float32),\n",
       " array([ 3.,  4.], dtype=float32),\n",
       " array([ 5.,  6.], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
